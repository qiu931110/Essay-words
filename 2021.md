
1：an alternative framework to self-attention ： 用于替换self-attention的框架
alternative：选择性的

2 lambda layers bypass expensive attention maps：lambda层绕过了昂贵的注意力地图
bypass：绕过

3 transforming available contexts into linear functions：将可用的上下文语境转换成线性函数
transforming into ：转换成
contexts：上下文语境

4 significantly outperform their convolutional and attentional counterparts on ImageNet classification：在ImageNet分类任务上明显胜过其卷积和注意力的对应操作
significantly outperform：明显胜过
counterparts：同行

5 offer a scalable remedy for high memory usage：为高内存使用提供了一个可扩展的补救措施
scalable 可扩展的
remedy 补救措施

6 impractical：不切实际的

7 prioritize：优先顺序

